{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import time\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import PIL\n",
    "import h5py\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
    "from tensorflow.keras.models import load_model\n",
    "from layers import BilinearUpSampling2D\n",
    "from loss import depth_loss_function\n",
    "from utils import predict\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument Parser\n",
    "parser = argparse.ArgumentParser(description='High Quality Monocular Depth Estimation via Transfer Learning')\n",
    "parser.add_argument('--model', default='nyu.h5', type=str, help='Trained Keras model file.')\n",
    "parser.add_argument('--traininput', default='training_images/*.jpg', type=str, help='Training input filename or folder.')\n",
    "parser.add_argument('--testinput', default='testing_image/*.jpg', type=str, help='Testing input filename or folder.')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "# Custom object needed for inference and training\n",
    "start = time.time()\n",
    "custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': depth_loss_function}\n",
    "\n",
    "print('Loading model...')\n",
    "\n",
    "# Load model into GPU / CPU\n",
    "model = load_model(args.model, custom_objects=custom_objects, compile=False)\n",
    "\n",
    "print('\\nModel loaded ({0}).'.format(args.model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Heatmap Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_with_resize(image_files):\n",
    "    loaded_images = []\n",
    "    for file in image_files:\n",
    "        im = Image.open( file )\n",
    "        im = im.resize((640, 480), PIL.Image.ANTIALIAS)\n",
    "        x = np.clip(np.asarray(im, dtype=float) / 255, 0, 1)\n",
    "        loaded_images.append(x)\n",
    "    return np.stack(loaded_images, axis=0)\n",
    "\n",
    "# Input images\n",
    "inputs = load_images_with_resize( glob.glob(args.traininput) )\n",
    "print('\\nLoaded ({0}) images of size {1}.'.format(inputs.shape[0], inputs.shape[1:]))\n",
    "\n",
    "# Compute results\n",
    "outputs = predict(model, inputs)\n",
    "\n",
    "end = time.time()\n",
    "print('It took: ', end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Relative and True Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(image, title=''):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    out = plt.imshow(image, cmap='plasma', interpolation='nearest')\n",
    "    out = plt.colorbar()\n",
    "    plt.title(title)\n",
    "\n",
    "# Delete every other row and column of the array so it matched dimensions of out predicted image\n",
    "def condense_image(image_src):\n",
    "    image = np.copy(image_src)\n",
    "    for row in reversed(range(len(image))):\n",
    "        if row % 2 != 0:\n",
    "            image = np.delete(image, row, 0)\n",
    "\n",
    "    for column in reversed(range(len(image[0]))):\n",
    "        if column % 2 != 0:\n",
    "            image = np.delete(image, column, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth(index: int):\n",
    "    f = h5py.File('nyu_depth_v2_labeled.mat', 'r')\n",
    "    nyu_depth_image = f['depths'][index]\n",
    "\n",
    "    return condense_image(nyu_depth_image.T)\n",
    "\n",
    "def get_rgb(index: int):\n",
    "    f = h5py.File('nyu_depth_v2_labeled.mat', 'r')\n",
    "    nyu_image = f['images'][index]\n",
    "\n",
    "    return nyu_image.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Image\n",
    "rgb_image = get_rgb(0)\n",
    "plt.figure(figsize=(10,5))\n",
    "out = plt.imshow(rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Ground-Truth Image\n",
    "true_depth_image = get_ground_truth(0)\n",
    "display(true_depth_image, \"True Depth Image (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Predicted Image\n",
    "def normalize_image(image):\n",
    "    min = np.min(image)\n",
    "    max = np.max(image)\n",
    "    return (image - min) / (max - min)\n",
    "\n",
    "predicted_image = normalize_image(np.asarray(outputs[0]))\n",
    "display(predicted_image, \"Relative Depth Estimation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Function Between Relative and True Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the two images as a function between each other\n",
    "x_axis = predicted_image.flatten()\n",
    "y_axis = true_depth_image.flatten()\n",
    "\n",
    "a, b = np.polyfit(x_axis, y_axis, 1)\n",
    "\n",
    "plt.scatter(x_axis, y_axis, s=0.5)\n",
    "plt.title('Relative vs True Depth')\n",
    "plt.xlabel('Relative Depth Value')\n",
    "plt.ylabel('True Depth Value (m)')\n",
    "plt.plot(x_axis, a*x_axis + b, linewidth=2, color='red')\n",
    "plt.text(0, 3.48, 'true_depth = ' + '{:.2f}'.format(b) + ' + {:.2f}'.format(a) + ' * relative_depth', size=7)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably add more code here to have the equation based on more than one image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Equation to New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the equation to a new image\n",
    "ground_truth_image = get_ground_truth(13) # NOTE: This index must match the image in /testing_image\n",
    "test_inputs = load_images_with_resize(glob.glob(args.testinput))\n",
    "\n",
    "print('\\nLoaded ({0}) images of size {1}.'.format(test_inputs.shape[0], test_inputs.shape[1:]))\n",
    "test_outputs = predict(model, test_inputs)\n",
    "print('Done with prediction(s)')\n",
    "\n",
    "relative_depth_image = normalize_image(np.asarray(test_outputs[0]))\n",
    "estimated_true_depth_image = a * relative_depth_image + b\n",
    "\n",
    "display(estimated_true_depth_image, \"True Depth Estimation (in meters)\")\n",
    "display(ground_truth_image, \"Ground Truth Image (in meters)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b793d7bc73bea712712f6f108b8aeff3d41b14825160568d437f9f2c3cae05f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
